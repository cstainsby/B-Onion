{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Am I the Asshole EDA\n",
    "This file will be dedicated to explore how to craft responses to posts in the subreddit r/AmITheAsshole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append(\"..\")\n",
    "\n",
    "# load enviornment variables for praw to work later\n",
    "load_dotenv(dotenv_path=Path(\"../settings.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to check if table exists\n",
    "def gcp_table_exists(client: bigquery.Client, table_id: str):\n",
    "    try:\n",
    "        client.get_table(table_id)  # Make an API request.\n",
    "        return True\n",
    "    except NotFound:\n",
    "        return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset\n",
    "Using Google Bigquery, create datasets for the data that is about to be loaded. The dataset will be called **AITA_dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_NAME = \"bonion\"\n",
    "DATASET_NAME = \"AITA_dataset\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all dataset ID's\n",
    "To prevent overwriting pre-existing datasets, get all dataset id's to check before any creation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in project bonion:\n",
      "\tAITA_dataset\n"
     ]
    }
   ],
   "source": [
    "# Get all datasets \n",
    "datasets = list(client.list_datasets())  # Make an API request.\n",
    "dataset_ids = [dataset.dataset_id for dataset in datasets]\n",
    "project = client.project\n",
    "\n",
    "if datasets:\n",
    "    print(\"Datasets in project {}:\".format(project))\n",
    "    for dataset in datasets:\n",
    "        print(\"\\t{}\".format(dataset.dataset_id))\n",
    "else:\n",
    "    print(\"{} project does not contain any datasets.\".format(project))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "if DATASET_NAME not in dataset_ids:\n",
    "    dataset = bigquery.Dataset(\"{}.{}\".format(PROJ_NAME, DATASET_NAME))\n",
    "    dataset.location = \"US\"\n",
    "\n",
    "    # send dataset to API for completion\n",
    "    initial_post_dataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
    "    print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Table\n",
    "The initial post for each of the comments will need to be stored to reference its content which dictated the reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table id definitions\n",
    "post_table_id = \"{}.{}.post_table\".format(PROJ_NAME, DATASET_NAME)\n",
    "post_reply_table_id = \"{}.{}.post_reply_table\".format(PROJ_NAME, DATASET_NAME)\n",
    "post_reply_top_children_table_id = \"{}.{}.post_reply_top_children\".format(PROJ_NAME, DATASET_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all Table ID's\n",
    "To prevent overwriting pre-existing tables, get all table id's to check before any creation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables contained in 'AITA_dataset':\n",
      "bonion.AITA_dataset.post_reply_table\n",
      "bonion.AITA_dataset.post_reply_top_children\n",
      "bonion.AITA_dataset.post_table\n"
     ]
    }
   ],
   "source": [
    "tables = list(client.list_tables(DATASET_NAME))  # Make an API request.\n",
    "table_ids = [table.table_id for table in tables]\n",
    "\n",
    "print(\"Tables contained in '{}':\".format(DATASET_NAME))\n",
    "for table in tables:\n",
    "    print(\"{}.{}.{}\".format(table.project, table.dataset_id, table.table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_table_schema = [\n",
    "    bigquery.SchemaField(\"reddit_post_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"post_title\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"post_self_text\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"upvotes\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"num_responses\", \"INTEGER\", mode=\"REQUIRED\")\n",
    "]\n",
    "\n",
    "if not gcp_table_exists(client, table_id=post_table_id): \n",
    "    post_table = bigquery.Table(post_table_id, schema=post_table_schema)\n",
    "    post_table.description = \"\"\"\n",
    "        A table which holds popular posts from the subreddit r/AITA\n",
    "    \"\"\"\n",
    "\n",
    "    table = client.create_table(post_table)\n",
    "    print(\n",
    "        \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Reply Table\n",
    "This table holds all of the responses for each of the posts in the post table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_reply_table_schema = [\n",
    "    bigquery.SchemaField(\"reddit_post_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"comment_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"comment_contents\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"upvotes\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"num_responses\", \"INTEGER\", mode=\"REQUIRED\")\n",
    "]\n",
    "\n",
    "if not gcp_table_exists(client, table_id=post_reply_table_id): \n",
    "    post_reply_table = bigquery.Table(post_reply_table_id, schema=post_reply_table_schema)\n",
    "    post_reply_table.description = \"\"\"\n",
    "        A table which holds the most popular replys to saved posts from the subreddit r/AITA\n",
    "    \"\"\"\n",
    "\n",
    "    table = client.create_table(post_reply_table)\n",
    "    print(\n",
    "        \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Reply Top Children\n",
    "This table will hold replys to the initial post reply. This will be used for also dictating the performance of a reply. Because there can be infinite replies to any given post or reply, each post reply id will be limited to some number of replies. These replies will likley be based off of the same metrics as the original post for \"quality\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_reply_top_children_table_schema = [\n",
    "    bigquery.SchemaField(\"parent_comment_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"comment_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"comment_contents\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"upvotes\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"num_responses\", \"INTEGER\", mode=\"REQUIRED\")\n",
    "]   \n",
    "\n",
    "if not gcp_table_exists(client, table_id=post_reply_top_children_table_id): \n",
    "    post_reply_top_children_table = bigquery.Table(post_reply_top_children_table_id, schema=post_reply_top_children_table_schema)\n",
    "    post_reply_top_children_table.description = \"\"\"\n",
    "        This table will hold replys to the initial post reply. \n",
    "        This will be used for also dictating the performance of a reply. \n",
    "        Because there can be infinite replies to any given post or reply, \n",
    "        each post reply id will be limited to some number of replies. \n",
    "        These replies will likley be based off of the same metrics as \n",
    "        the original post for \"quality\". \n",
    "    \"\"\"\n",
    "\n",
    "    table = client.create_table(post_reply_top_children_table)\n",
    "    print(\n",
    "        \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Data\n",
    "Using my PrawInstance Object, I will be collecting the top posts from the subreddit. I will be storing this data in google bigquery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'praw_instance' from '/home/cstainsby/class/dataProj/bonion/src/notebooks/../praw_instance.py'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import praw_instance\n",
    "importlib.reload(praw_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_name = \"amitheasshole\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "praw_inst = praw_instance.PrawInstance()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Top 1000 Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10000_posts = praw_instance.get_top_by_subreddit(praw_inst, subreddit_name, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full data shape (998, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reddit_post_id</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_self_text</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>num_responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ocx94s</td>\n",
       "      <td>AITA for telling my wife the lock on my daught...</td>\n",
       "      <td>My brother in-law (Sammy) lost his home shortl...</td>\n",
       "      <td>81016</td>\n",
       "      <td>5279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d6xoro</td>\n",
       "      <td>META: This sub is moving towards a value syste...</td>\n",
       "      <td>I’ve enjoyed reading and posting on this sub f...</td>\n",
       "      <td>80921</td>\n",
       "      <td>6190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>azvko1</td>\n",
       "      <td>UPDATE, AITA for despising my mentally handica...</td>\n",
       "      <td>I'm back like I said I would be,. My [original...</td>\n",
       "      <td>72781</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gr8bp3</td>\n",
       "      <td>AITA For suing my girlfriend after she had my ...</td>\n",
       "      <td>I'll try to keep this short. I had a [1967 Imp...</td>\n",
       "      <td>70807</td>\n",
       "      <td>2757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x2k5kv</td>\n",
       "      <td>AITA for bringing my SIL’s wallet to the resta...</td>\n",
       "      <td>Edit: update on profile\\n\\nMy (f28) SIL “Amy” ...</td>\n",
       "      <td>69786</td>\n",
       "      <td>3822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cjetsa</td>\n",
       "      <td>UPDATE: AITA for wanting to go to the funeral ...</td>\n",
       "      <td>I want to sincerely thank everyone who comment...</td>\n",
       "      <td>67573</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e5k3z2</td>\n",
       "      <td>AITA for pretending to get fired when customer...</td>\n",
       "      <td>I am a high schooler with a weekend job at a c...</td>\n",
       "      <td>63528</td>\n",
       "      <td>3621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zvmflw</td>\n",
       "      <td>AITA for bringing up my brother's \"premature\" ...</td>\n",
       "      <td>I am a nurse practitioner and I am the primary...</td>\n",
       "      <td>59184</td>\n",
       "      <td>3370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>flan73</td>\n",
       "      <td>UPDATE: WIBTA if I took over planning my own f...</td>\n",
       "      <td>Hello, everyone. First of all, thank you all f...</td>\n",
       "      <td>58487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dhfeg9</td>\n",
       "      <td>AITA for making a dad joke?</td>\n",
       "      <td>Note. My step-daughter, Madeline, was about a ...</td>\n",
       "      <td>56950</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reddit_post_id                                         post_title  \\\n",
       "0         ocx94s  AITA for telling my wife the lock on my daught...   \n",
       "1         d6xoro  META: This sub is moving towards a value syste...   \n",
       "2         azvko1  UPDATE, AITA for despising my mentally handica...   \n",
       "3         gr8bp3  AITA For suing my girlfriend after she had my ...   \n",
       "4         x2k5kv  AITA for bringing my SIL’s wallet to the resta...   \n",
       "5         cjetsa  UPDATE: AITA for wanting to go to the funeral ...   \n",
       "6         e5k3z2  AITA for pretending to get fired when customer...   \n",
       "7         zvmflw  AITA for bringing up my brother's \"premature\" ...   \n",
       "8         flan73  UPDATE: WIBTA if I took over planning my own f...   \n",
       "9         dhfeg9                        AITA for making a dad joke?   \n",
       "\n",
       "                                      post_self_text upvotes num_responses  \n",
       "0  My brother in-law (Sammy) lost his home shortl...   81016          5279  \n",
       "1  I’ve enjoyed reading and posting on this sub f...   80921          6190  \n",
       "2  I'm back like I said I would be,. My [original...   72781          1985  \n",
       "3  I'll try to keep this short. I had a [1967 Imp...   70807          2757  \n",
       "4  Edit: update on profile\\n\\nMy (f28) SIL “Amy” ...   69786          3822  \n",
       "5  I want to sincerely thank everyone who comment...   67573             2  \n",
       "6  I am a high schooler with a weekend job at a c...   63528          3621  \n",
       "7  I am a nurse practitioner and I am the primary...   59184          3370  \n",
       "8  Hello, everyone. First of all, thank you all f...   58487             2  \n",
       "9  Note. My step-daughter, Madeline, was about a ...   56950          1995  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the top 1000 posts into gcp\n",
    "# convert data into json rows \n",
    "post_table_df = praw_instance.post_dict_to_df(top_10000_posts)\n",
    "\n",
    "post_table_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 998 entries, 0 to 997\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   reddit_post_id  998 non-null    object\n",
      " 1   post_title      998 non-null    object\n",
      " 2   post_self_text  998 non-null    object\n",
      " 3   upvotes         998 non-null    int64 \n",
      " 4   num_responses   998 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 39.1+ KB\n"
     ]
    }
   ],
   "source": [
    "post_table_df[\"reddit_post_id\"] = post_table_df[\"reddit_post_id\"].astype(str)\n",
    "post_table_df[\"post_title\"] = post_table_df[\"post_title\"].astype(str)\n",
    "post_table_df[\"post_self_text\"] = post_table_df[\"post_self_text\"].astype(str)\n",
    "post_table_df[\"upvotes\"] = post_table_df[\"upvotes\"].astype(int)\n",
    "post_table_df[\"num_responses\"] = post_table_df[\"num_responses\"].astype(int)\n",
    "post_table_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12336.19it/s]\n"
     ]
    }
   ],
   "source": [
    "pandas_gbq.to_gbq(post_table_df, post_table_id, project_id=PROJ_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Top Comments for the top posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reddit_post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jyk2ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ukzctc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u90414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>socrlh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hf4bc4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reddit_post_id\n",
       "0         jyk2ac\n",
       "1         ukzctc\n",
       "2         u90414\n",
       "3         socrlh\n",
       "4         hf4bc4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top post ids\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT reddit_post_id\n",
    "    FROM {}\n",
    "\"\"\".format(post_table_id)\n",
    "\n",
    "post_table_df = pd.read_gbq(query, project_id=PROJ_NAME)\n",
    "\n",
    "post_table_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
