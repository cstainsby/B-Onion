{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AITA Data Loading\n",
    "This file will be dedicated pushing an initial load of reddit data to Google big query. Further data changes will occur later in other ipynb files like *AITA_GCPDataModifications.ipynb* \n",
    "\n",
    "**NOTE:** Do not run this file again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append(\"..\")\n",
    "\n",
    "# load enviornment variables for praw to work later\n",
    "load_dotenv(dotenv_path=Path(\"../settings.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to check if table exists\n",
    "def gcp_table_exists(client: bigquery.Client, table_id: str):\n",
    "    try:\n",
    "        client.get_table(table_id)  # Make an API request.\n",
    "        return True\n",
    "    except NotFound:\n",
    "        return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset\n",
    "Using Google Bigquery, create datasets for the data that is about to be loaded. The dataset will be called **AITA_dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_NAME = \"bonion\"\n",
    "DATASET_NAME = \"AITA_dataset\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all dataset ID's\n",
    "To prevent overwriting pre-existing datasets, get all dataset id's to check before any creation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in project bonion:\n",
      "\tAITA_dataset\n"
     ]
    }
   ],
   "source": [
    "# Get all datasets \n",
    "datasets = list(client.list_datasets())  # Make an API request.\n",
    "dataset_ids = [dataset.dataset_id for dataset in datasets]\n",
    "project = client.project\n",
    "\n",
    "if datasets:\n",
    "    print(\"Datasets in project {}:\".format(project))\n",
    "    for dataset in datasets:\n",
    "        print(\"\\t{}\".format(dataset.dataset_id))\n",
    "else:\n",
    "    print(\"{} project does not contain any datasets.\".format(project))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "if DATASET_NAME not in dataset_ids:\n",
    "    dataset = bigquery.Dataset(\"{}.{}\".format(PROJ_NAME, DATASET_NAME))\n",
    "    dataset.location = \"US\"\n",
    "\n",
    "    # send dataset to API for completion\n",
    "    initial_post_dataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
    "    print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Table\n",
    "The initial post for each of the comments will need to be stored to reference its content which dictated the reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table id definitions\n",
    "post_table_id = \"{}.{}.post_table\".format(PROJ_NAME, DATASET_NAME)\n",
    "comment_table_id = \"{}.{}.comment_table\".format(PROJ_NAME, DATASET_NAME)\n",
    "reply_table_id = \"{}.{}.reply_table\".format(PROJ_NAME, DATASET_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all Table ID's\n",
    "To prevent overwriting pre-existing tables, get all table id's to check before any creation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables contained in 'AITA_dataset':\n",
      "bonion.AITA_dataset.post_table\n"
     ]
    }
   ],
   "source": [
    "tables = list(client.list_tables(DATASET_NAME))  # Make an API request.\n",
    "table_ids = [table.table_id for table in tables]\n",
    "\n",
    "print(\"Tables contained in '{}':\".format(DATASET_NAME))\n",
    "for table in tables:\n",
    "    print(\"{}.{}.{}\".format(table.project, table.dataset_id, table.table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_table_schema = [\n",
    "    bigquery.SchemaField(\"reddit_post_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"post_title\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"post_self_text\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"upvotes\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"num_responses\", \"INTEGER\", mode=\"REQUIRED\")\n",
    "]\n",
    "\n",
    "if not gcp_table_exists(client, table_id=post_table_id): \n",
    "    post_table = bigquery.Table(post_table_id, schema=post_table_schema)\n",
    "    post_table.description = \"\"\"\n",
    "        A table which holds popular posts from the subreddit r/AITA\n",
    "    \"\"\"\n",
    "\n",
    "    table = client.create_table(post_table)\n",
    "    print(\n",
    "        \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Table\n",
    "This table holds all of the responses for each of the posts in the post table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table bonion.AITA_dataset.comment_table\n"
     ]
    }
   ],
   "source": [
    "comment_table_schema = [\n",
    "    bigquery.SchemaField(\"comment_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"parent_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"content\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"upvotes\", \"INTEGER\", mode=\"REQUIRED\")\n",
    "]\n",
    "\n",
    "if not gcp_table_exists(client, table_id=comment_table_id): \n",
    "    post_reply_table = bigquery.Table(comment_table_id, schema=comment_table_schema)\n",
    "    post_reply_table.description = \"\"\"\n",
    "        A table which holds the most popular replys to saved posts from the subreddit r/AITA\n",
    "    \"\"\"\n",
    "\n",
    "    table = client.create_table(post_reply_table)\n",
    "    print(\n",
    "        \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reply Table\n",
    "This table will hold replys to the initial post reply. This will be used for also dictating the performance of a reply. Because there can be infinite replies to any given post or reply, each post reply id will be limited to some number of replies. These replies will likley be based off of the same metrics as the original post for \"quality\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table bonion.AITA_dataset.reply_table\n"
     ]
    }
   ],
   "source": [
    "reply_table_schema = [\n",
    "    bigquery.SchemaField(\"reply_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"parent_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"content\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"upvotes\", \"INTEGER\", mode=\"REQUIRED\")\n",
    "]   \n",
    "\n",
    "if not gcp_table_exists(client, table_id=reply_table_id): \n",
    "    post_reply_top_children_table = bigquery.Table(reply_table_id, schema=reply_table_schema)\n",
    "    post_reply_top_children_table.description = \"\"\"\n",
    "        This table will hold replys to the initial post reply. \n",
    "        This will be used for also dictating the performance of a reply. \n",
    "        Because there can be infinite replies to any given post or reply, \n",
    "        each post reply id will be limited to some number of replies. \n",
    "        These replies will likley be based off of the same metrics as \n",
    "        the original post for \"quality\". \n",
    "    \"\"\"\n",
    "\n",
    "    table = client.create_table(post_reply_top_children_table)\n",
    "    print(\n",
    "        \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Data\n",
    "Using my PrawInstance Object, I will be collecting the top posts from the subreddit. I will be storing this data in google bigquery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'praw_instance' from '/home/cstainsby/class/dataProj/bonion/src/notebooks/../praw_instance.py'>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import praw_instance\n",
    "importlib.reload(praw_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_name = \"amitheasshole\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "praw_inst = praw_instance.PrawInstance()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Top 1000 Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m top_10000_posts \u001b[39m=\u001b[39m praw_instance\u001b[39m.\u001b[39;49mget_top_by_subreddit(praw_inst, subreddit_name, limit\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[0;32m~/class/dataProj/bonion/src/notebooks/../praw_instance.py:54\u001b[0m, in \u001b[0;36mget_top_by_subreddit\u001b[0;34m(praw_inst, subreddit_name, limit)\u001b[0m\n\u001b[1;32m     52\u001b[0m top_by_sub \u001b[39m=\u001b[39m {}\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m praw_inst \u001b[39mand\u001b[39;00m subreddit_name \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 54\u001b[0m     post_obj_lst \u001b[39m=\u001b[39m [top_post \u001b[39mfor\u001b[39;00m top_post \u001b[39min\u001b[39;00m praw_inst()\u001b[39m.\u001b[39msubreddit(subreddit_name)\u001b[39m.\u001b[39mtop(limit\u001b[39m=\u001b[39mlimit) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m top_post\u001b[39m.\u001b[39mstickied]\n\u001b[1;32m     55\u001b[0m     \u001b[39mfor\u001b[39;00m post \u001b[39min\u001b[39;00m post_obj_lst:\n\u001b[1;32m     56\u001b[0m         top_by_sub[post] \u001b[39m=\u001b[39m {\n\u001b[1;32m     57\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m: post\u001b[39m.\u001b[39mtitle,\n\u001b[1;32m     58\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mupvotes\u001b[39m\u001b[39m\"\u001b[39m: post\u001b[39m.\u001b[39mups,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnumcomments\u001b[39m\u001b[39m\"\u001b[39m: post\u001b[39m.\u001b[39mnum_comments\n\u001b[1;32m     62\u001b[0m         }\n",
      "File \u001b[0;32m~/class/dataProj/bonion/src/notebooks/../praw_instance.py:54\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m top_by_sub \u001b[39m=\u001b[39m {}\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m praw_inst \u001b[39mand\u001b[39;00m subreddit_name \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 54\u001b[0m     post_obj_lst \u001b[39m=\u001b[39m [top_post \u001b[39mfor\u001b[39;00m top_post \u001b[39min\u001b[39;00m praw_inst()\u001b[39m.\u001b[39msubreddit(subreddit_name)\u001b[39m.\u001b[39mtop(limit\u001b[39m=\u001b[39mlimit) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m top_post\u001b[39m.\u001b[39mstickied]\n\u001b[1;32m     55\u001b[0m     \u001b[39mfor\u001b[39;00m post \u001b[39min\u001b[39;00m post_obj_lst:\n\u001b[1;32m     56\u001b[0m         top_by_sub[post] \u001b[39m=\u001b[39m {\n\u001b[1;32m     57\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m: post\u001b[39m.\u001b[39mtitle,\n\u001b[1;32m     58\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mupvotes\u001b[39m\u001b[39m\"\u001b[39m: post\u001b[39m.\u001b[39mups,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnumcomments\u001b[39m\u001b[39m\"\u001b[39m: post\u001b[39m.\u001b[39mnum_comments\n\u001b[1;32m     62\u001b[0m         }\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/praw/models/listing/generator.py:63\u001b[0m, in \u001b[0;36mListingGenerator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m()\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_listing \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_list_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_listing):\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_batch()\n\u001b[1;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_list_index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     66\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39myielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/praw/models/listing/generator.py:89\u001b[0m, in \u001b[0;36mListingGenerator._next_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exhausted:\n\u001b[1;32m     87\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m()\n\u001b[0;32m---> 89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_listing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reddit\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl, params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[1;32m     90\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_listing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extract_sublist(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_listing)\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_list_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/praw/util/deprecate_args.py:43\u001b[0m, in \u001b[0;36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     arg_string \u001b[39m=\u001b[39m _generate_arg_string(_old_args[: \u001b[39mlen\u001b[39m(args)])\n\u001b[1;32m     37\u001b[0m     warn(\n\u001b[1;32m     38\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPositional arguments for \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m will no longer be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m supported in PRAW 8.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCall this function with \u001b[39m\u001b[39m{\u001b[39;00marg_string\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m         \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     42\u001b[0m     )\n\u001b[0;32m---> 43\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(\u001b[39mzip\u001b[39;49m(_old_args, args)), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/praw/reddit.py:712\u001b[0m, in \u001b[0;36mReddit.get\u001b[0;34m(self, path, params)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[39m@_deprecate_args\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    700\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\n\u001b[1;32m    701\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    704\u001b[0m     params: Optional[Union[\u001b[39mstr\u001b[39m, Dict[\u001b[39mstr\u001b[39m, Union[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    705\u001b[0m ):\n\u001b[1;32m    706\u001b[0m     \u001b[39m\"\"\"Return parsed objects returned from a GET request to ``path``.\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \n\u001b[1;32m    708\u001b[0m \u001b[39m    :param path: The path to fetch.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[39m    :param params: The query parameters to add to the request (default: ``None``).\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \n\u001b[1;32m    711\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 712\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_objectify_request(method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, params\u001b[39m=\u001b[39;49mparams, path\u001b[39m=\u001b[39;49mpath)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/praw/reddit.py:517\u001b[0m, in \u001b[0;36mReddit._objectify_request\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_objectify_request\u001b[39m(\n\u001b[1;32m    492\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    493\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m     path: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    500\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    501\u001b[0m     \u001b[39m\"\"\"Run a request through the ``Objector``.\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \n\u001b[1;32m    503\u001b[0m \u001b[39m    :param data: Dictionary, bytes, or file-like object to send in the body of the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m \n\u001b[1;32m    515\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_objector\u001b[39m.\u001b[39mobjectify(\n\u001b[0;32m--> 517\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    518\u001b[0m             data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    519\u001b[0m             files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    520\u001b[0m             json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    521\u001b[0m             method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    522\u001b[0m             params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    523\u001b[0m             path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m    524\u001b[0m         )\n\u001b[1;32m    525\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/praw/util/deprecate_args.py:43\u001b[0m, in \u001b[0;36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     arg_string \u001b[39m=\u001b[39m _generate_arg_string(_old_args[: \u001b[39mlen\u001b[39m(args)])\n\u001b[1;32m     37\u001b[0m     warn(\n\u001b[1;32m     38\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPositional arguments for \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m will no longer be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m supported in PRAW 8.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCall this function with \u001b[39m\u001b[39m{\u001b[39;00marg_string\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m         \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     42\u001b[0m     )\n\u001b[0;32m---> 43\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(\u001b[39mzip\u001b[39;49m(_old_args, args)), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/praw/reddit.py:941\u001b[0m, in \u001b[0;36mReddit.request\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[39mraise\u001b[39;00m ClientException(\u001b[39m\"\u001b[39m\u001b[39mAt most one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    940\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 941\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_core\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    942\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    943\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    944\u001b[0m         json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    945\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    946\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    947\u001b[0m         path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m    948\u001b[0m     )\n\u001b[1;32m    949\u001b[0m \u001b[39mexcept\u001b[39;00m BadRequest \u001b[39mas\u001b[39;00m exception:\n\u001b[1;32m    950\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/prawcore/sessions.py:330\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, path, data, files, json, params, timeout)\u001b[0m\n\u001b[1;32m    328\u001b[0m     json[\u001b[39m\"\u001b[39m\u001b[39mapi_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    329\u001b[0m url \u001b[39m=\u001b[39m urljoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requestor\u001b[39m.\u001b[39moauth_url, path)\n\u001b[0;32m--> 330\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request_with_retries(\n\u001b[1;32m    331\u001b[0m     data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    332\u001b[0m     files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    333\u001b[0m     json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    334\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    335\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    336\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    337\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    338\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/prawcore/sessions.py:228\u001b[0m, in \u001b[0;36mSession._request_with_retries\u001b[0;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[1;32m    226\u001b[0m retry_strategy_state\u001b[39m.\u001b[39msleep()\n\u001b[1;32m    227\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_request(data, method, params, url)\n\u001b[0;32m--> 228\u001b[0m response, saved_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    229\u001b[0m     data,\n\u001b[1;32m    230\u001b[0m     files,\n\u001b[1;32m    231\u001b[0m     json,\n\u001b[1;32m    232\u001b[0m     method,\n\u001b[1;32m    233\u001b[0m     params,\n\u001b[1;32m    234\u001b[0m     retry_strategy_state,\n\u001b[1;32m    235\u001b[0m     timeout,\n\u001b[1;32m    236\u001b[0m     url,\n\u001b[1;32m    237\u001b[0m )\n\u001b[1;32m    239\u001b[0m do_retry \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    241\u001b[0m     response \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m codes[\u001b[39m\"\u001b[39m\u001b[39munauthorized\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    243\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/prawcore/sessions.py:185\u001b[0m, in \u001b[0;36mSession._make_request\u001b[0;34m(self, data, files, json, method, params, retry_strategy_state, timeout, url)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_request\u001b[39m(\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    175\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m     url,\n\u001b[1;32m    183\u001b[0m ):\n\u001b[1;32m    184\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rate_limiter\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m    186\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_requestor\u001b[39m.\u001b[39;49mrequest,\n\u001b[1;32m    187\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_header_callback,\n\u001b[1;32m    188\u001b[0m             method,\n\u001b[1;32m    189\u001b[0m             url,\n\u001b[1;32m    190\u001b[0m             allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    191\u001b[0m             data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    192\u001b[0m             files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    193\u001b[0m             json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    194\u001b[0m             params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    195\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    196\u001b[0m         )\n\u001b[1;32m    197\u001b[0m         log\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    198\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mResponse: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mcontent-length\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m bytes)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    200\u001b[0m         )\n\u001b[1;32m    201\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/prawcore/rate_limit.py:34\u001b[0m, in \u001b[0;36mRateLimiter.call\u001b[0;34m(self, request_function, set_header_callback, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelay()\n\u001b[1;32m     33\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m set_header_callback()\n\u001b[0;32m---> 34\u001b[0m response \u001b[39m=\u001b[39m request_function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(response\u001b[39m.\u001b[39mheaders)\n\u001b[1;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/prawcore/requestor.py:58\u001b[0m, in \u001b[0;36mRequestor.request\u001b[0;34m(self, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m\"\"\"Issue the HTTP request capturing any errors that may occur.\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_http\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m     59\u001b[0m         \u001b[39m*\u001b[39;49margs, timeout\u001b[39m=\u001b[39;49mtimeout \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m     60\u001b[0m     )\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     62\u001b[0m     \u001b[39mraise\u001b[39;00m RequestException(exc, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:665\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    664\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 665\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    666\u001b[0m     conn,\n\u001b[1;32m    667\u001b[0m     method,\n\u001b[1;32m    668\u001b[0m     url,\n\u001b[1;32m    669\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    670\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    671\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    672\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    673\u001b[0m )\n\u001b[1;32m    675\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:421\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    416\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    417\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    418\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    419\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    420\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    422\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    423\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:416\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    417\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    418\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    419\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    420\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1349\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1350\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "top_10000_posts = praw_instance.get_top_by_subreddit(praw_inst, subreddit_name, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the top 1000 posts into gcp\n",
    "# convert data into json rows \n",
    "post_table_df = praw_instance.post_dict_to_df(top_10000_posts)\n",
    "\n",
    "post_table_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast table columns to type\n",
    "post_table_df[\"reddit_post_id\"] = post_table_df[\"reddit_post_id\"].astype(str)\n",
    "post_table_df[\"post_title\"] = post_table_df[\"post_title\"].astype(str)\n",
    "post_table_df[\"post_self_text\"] = post_table_df[\"post_self_text\"].astype(str)\n",
    "post_table_df[\"upvotes\"] = post_table_df[\"upvotes\"].astype(int)\n",
    "post_table_df[\"num_responses\"] = post_table_df[\"num_responses\"].astype(int)\n",
    "post_table_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'post_table_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pandas_gbq\u001b[39m.\u001b[39mto_gbq(post_table_df, post_table_id, project_id\u001b[39m=\u001b[39mPROJ_NAME)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'post_table_df' is not defined"
     ]
    }
   ],
   "source": [
    "pandas_gbq.to_gbq(post_table_df, post_table_id, project_id=PROJ_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Top Comments and Replies for the top posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reddit_post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jyk2ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ukzctc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u90414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>socrlh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reddit_post_id\n",
       "0         jyk2ac\n",
       "1         ukzctc\n",
       "2         u90414\n",
       "3         socrlh"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top post ids\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT reddit_post_id\n",
    "    FROM {}\n",
    "\"\"\".format(post_table_id)\n",
    "\n",
    "post_table_ids_df = pd.read_gbq(query, project_id=PROJ_NAME)\n",
    "\n",
    "post_table_ids_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling 10 comments and 5 replies for each comment:\n",
      "\tOn index 0 of 249\n",
      "\tOn index 1 of 249\n",
      "\tOn index 2 of 249\n",
      "\tOn index 3 of 249\n",
      "\tOn index 4 of 249\n",
      "\tOn index 5 of 249\n",
      "\tOn index 6 of 249\n",
      "\tOn index 7 of 249\n",
      "\tOn index 8 of 249\n",
      "\tOn index 9 of 249\n",
      "\tOn index 10 of 249\n",
      "\tOn index 11 of 249\n",
      "\tOn index 12 of 249\n",
      "\tOn index 13 of 249\n",
      "\tOn index 14 of 249\n",
      "\tOn index 15 of 249\n",
      "\tOn index 16 of 249\n",
      "\tOn index 17 of 249\n",
      "\tOn index 18 of 249\n",
      "\tOn index 19 of 249\n",
      "\tOn index 20 of 249\n",
      "\tOn index 21 of 249\n",
      "\tOn index 22 of 249\n",
      "\tOn index 23 of 249\n",
      "\tOn index 24 of 249\n",
      "\tOn index 25 of 249\n",
      "\tOn index 26 of 249\n",
      "\tOn index 27 of 249\n",
      "\tOn index 28 of 249\n",
      "\tOn index 29 of 249\n",
      "\tOn index 30 of 249\n",
      "\tOn index 31 of 249\n",
      "\tOn index 32 of 249\n",
      "\tOn index 33 of 249\n",
      "\tOn index 34 of 249\n",
      "\tOn index 35 of 249\n",
      "\tOn index 36 of 249\n",
      "\tOn index 37 of 249\n",
      "\tOn index 38 of 249\n",
      "\tOn index 39 of 249\n",
      "\tOn index 40 of 249\n",
      "\tOn index 41 of 249\n",
      "\tOn index 42 of 249\n",
      "\tOn index 43 of 249\n",
      "\tOn index 44 of 249\n",
      "\tOn index 45 of 249\n",
      "\tOn index 46 of 249\n",
      "\tOn index 47 of 249\n",
      "\tOn index 48 of 249\n",
      "\tOn index 49 of 249\n",
      "\tOn index 50 of 249\n",
      "\tOn index 51 of 249\n",
      "\tOn index 52 of 249\n",
      "\tOn index 53 of 249\n",
      "\tOn index 54 of 249\n",
      "\tOn index 55 of 249\n",
      "\tOn index 56 of 249\n",
      "\tOn index 57 of 249\n",
      "\tOn index 58 of 249\n",
      "\tOn index 59 of 249\n",
      "\tOn index 60 of 249\n",
      "\tOn index 61 of 249\n",
      "\tOn index 62 of 249\n",
      "\tOn index 63 of 249\n",
      "\tOn index 64 of 249\n",
      "\tOn index 65 of 249\n",
      "\tOn index 66 of 249\n",
      "\tOn index 67 of 249\n",
      "\tOn index 68 of 249\n",
      "\tOn index 69 of 249\n",
      "\tOn index 70 of 249\n",
      "\tOn index 71 of 249\n",
      "\tOn index 72 of 249\n",
      "\tOn index 73 of 249\n",
      "\tOn index 74 of 249\n",
      "\tOn index 75 of 249\n",
      "\tOn index 76 of 249\n",
      "\tOn index 77 of 249\n",
      "\tOn index 78 of 249\n",
      "\tOn index 79 of 249\n",
      "\tOn index 80 of 249\n",
      "\tOn index 81 of 249\n",
      "\tOn index 82 of 249\n",
      "\tOn index 83 of 249\n",
      "\tOn index 84 of 249\n",
      "\tOn index 85 of 249\n",
      "\tOn index 86 of 249\n",
      "\tOn index 87 of 249\n",
      "\tOn index 88 of 249\n",
      "\tOn index 89 of 249\n",
      "\tOn index 90 of 249\n",
      "\tOn index 91 of 249\n",
      "\tOn index 92 of 249\n",
      "\tOn index 93 of 249\n",
      "\tOn index 94 of 249\n",
      "\tOn index 95 of 249\n",
      "\tOn index 96 of 249\n",
      "\tOn index 97 of 249\n",
      "\tOn index 98 of 249\n",
      "\tOn index 99 of 249\n",
      "\tOn index 100 of 249\n",
      "\tOn index 101 of 249\n",
      "\tOn index 102 of 249\n",
      "\tOn index 103 of 249\n",
      "\tOn index 104 of 249\n",
      "\tOn index 105 of 249\n",
      "\tOn index 106 of 249\n",
      "\tOn index 107 of 249\n",
      "\tOn index 108 of 249\n",
      "\tOn index 109 of 249\n",
      "\tOn index 110 of 249\n",
      "\tOn index 111 of 249\n",
      "\tOn index 112 of 249\n",
      "\tOn index 113 of 249\n",
      "\tOn index 114 of 249\n",
      "\tOn index 115 of 249\n",
      "\tOn index 116 of 249\n",
      "\tOn index 117 of 249\n",
      "\tOn index 118 of 249\n",
      "\tOn index 119 of 249\n",
      "\tOn index 120 of 249\n",
      "\tOn index 121 of 249\n",
      "\tOn index 122 of 249\n",
      "\tOn index 123 of 249\n",
      "\tOn index 124 of 249\n",
      "\tOn index 125 of 249\n",
      "\tOn index 126 of 249\n",
      "\tOn index 127 of 249\n",
      "\tOn index 128 of 249\n",
      "\tOn index 129 of 249\n",
      "\tOn index 130 of 249\n",
      "\tOn index 131 of 249\n",
      "\tOn index 132 of 249\n",
      "\tOn index 133 of 249\n",
      "\tOn index 134 of 249\n",
      "\tOn index 135 of 249\n",
      "\tOn index 136 of 249\n",
      "\tOn index 137 of 249\n",
      "\tOn index 138 of 249\n",
      "\tOn index 139 of 249\n",
      "\tOn index 140 of 249\n",
      "\tOn index 141 of 249\n",
      "\tOn index 142 of 249\n",
      "\tOn index 143 of 249\n",
      "\tOn index 144 of 249\n",
      "\tOn index 145 of 249\n",
      "\tOn index 146 of 249\n",
      "\tOn index 147 of 249\n",
      "\tOn index 148 of 249\n",
      "\tOn index 149 of 249\n",
      "\tOn index 150 of 249\n",
      "\tOn index 151 of 249\n",
      "\tOn index 152 of 249\n",
      "\tOn index 153 of 249\n",
      "\tOn index 154 of 249\n",
      "\tOn index 155 of 249\n",
      "\tOn index 156 of 249\n",
      "\tOn index 157 of 249\n",
      "\tOn index 158 of 249\n",
      "\tOn index 159 of 249\n",
      "\tOn index 160 of 249\n",
      "\tOn index 161 of 249\n",
      "\tOn index 162 of 249\n",
      "\tOn index 163 of 249\n",
      "\tOn index 164 of 249\n",
      "\tOn index 165 of 249\n",
      "\tOn index 166 of 249\n",
      "\tOn index 167 of 249\n",
      "\tOn index 168 of 249\n",
      "\tOn index 169 of 249\n",
      "\tOn index 170 of 249\n",
      "\tOn index 171 of 249\n",
      "\tOn index 172 of 249\n",
      "\tOn index 173 of 249\n",
      "\tOn index 174 of 249\n",
      "\tOn index 175 of 249\n",
      "\tOn index 176 of 249\n",
      "\tOn index 177 of 249\n",
      "\tOn index 178 of 249\n",
      "\tOn index 179 of 249\n",
      "\tOn index 180 of 249\n",
      "\tOn index 181 of 249\n",
      "\tOn index 182 of 249\n",
      "\tOn index 183 of 249\n",
      "\tOn index 184 of 249\n",
      "\tOn index 185 of 249\n",
      "\tOn index 186 of 249\n",
      "\tOn index 187 of 249\n",
      "\tOn index 188 of 249\n",
      "\tOn index 189 of 249\n",
      "\tOn index 190 of 249\n",
      "\tOn index 191 of 249\n",
      "\tOn index 192 of 249\n",
      "\tOn index 193 of 249\n",
      "\tOn index 194 of 249\n",
      "\tOn index 195 of 249\n",
      "\tOn index 196 of 249\n",
      "\tOn index 197 of 249\n",
      "\tOn index 198 of 249\n",
      "\tOn index 199 of 249\n",
      "\tOn index 200 of 249\n",
      "\tOn index 201 of 249\n",
      "\tOn index 202 of 249\n",
      "\tOn index 203 of 249\n",
      "\tOn index 204 of 249\n",
      "\tOn index 205 of 249\n",
      "\tOn index 206 of 249\n",
      "\tOn index 207 of 249\n",
      "\tOn index 208 of 249\n",
      "\tOn index 209 of 249\n",
      "\tOn index 210 of 249\n",
      "\tOn index 211 of 249\n",
      "\tOn index 212 of 249\n",
      "\tOn index 213 of 249\n",
      "\tOn index 214 of 249\n",
      "\tOn index 215 of 249\n",
      "\tOn index 216 of 249\n",
      "\tOn index 217 of 249\n",
      "\tOn index 218 of 249\n",
      "\tOn index 219 of 249\n",
      "\tOn index 220 of 249\n",
      "\tOn index 221 of 249\n",
      "\tOn index 222 of 249\n",
      "\tOn index 223 of 249\n",
      "\tOn index 224 of 249\n",
      "\tOn index 225 of 249\n",
      "\tOn index 226 of 249\n",
      "\tOn index 227 of 249\n",
      "\tOn index 228 of 249\n",
      "\tOn index 229 of 249\n",
      "\tOn index 230 of 249\n",
      "\tOn index 231 of 249\n",
      "\tOn index 232 of 249\n",
      "\tOn index 233 of 249\n",
      "\tOn index 234 of 249\n",
      "\tOn index 235 of 249\n",
      "\tOn index 236 of 249\n",
      "\tOn index 237 of 249\n",
      "\tOn index 238 of 249\n",
      "\tOn index 239 of 249\n",
      "\tOn index 240 of 249\n",
      "\tOn index 241 of 249\n",
      "\tOn index 242 of 249\n",
      "\tOn index 243 of 249\n",
      "\tOn index 244 of 249\n",
      "\tOn index 245 of 249\n",
      "\tOn index 246 of 249\n",
      "\tOn index 247 of 249\n",
      "\tOn index 248 of 249\n",
      "\tOn index 249 of 249\n"
     ]
    }
   ],
   "source": [
    "comment_and_reply_dict_list = []\n",
    "\n",
    "# I will batch the groups of comments I'm grabbing\n",
    "# so far I have pulled indices 0 thru 300\n",
    "start_index = 51 \n",
    "stop_index = 300\n",
    "\n",
    "comment_limit = 10\n",
    "reply_limit = 5\n",
    "\n",
    "print(\"Pulling {} comments and {} replies for each comment:\".format(comment_limit, reply_limit))\n",
    "for index, row in post_table_ids_df.iterrows():\n",
    "    if index >= start_index and index <= stop_index: \n",
    "        print(\"\\tOn index {} of {}\".format(index - start_index, stop_index - start_index))\n",
    "        comment_and_reply_dict = praw_instance.get_top_comments_and_top_replies_by_post_id(\n",
    "            praw_inst,\n",
    "            row[\"reddit_post_id\"],\n",
    "            comment_limit=comment_limit,\n",
    "            reply_limit=reply_limit\n",
    "        )\n",
    "\n",
    "        comment_and_reply_dict_list.append(comment_and_reply_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data to a dataframe\n",
    "full_comment_list, full_reply_list = [], []\n",
    "for post_i, comment_and_replies_dict in enumerate(comment_and_reply_dict_list):\n",
    "    comment_df_at_post_i, reply_df_at_post_i =  praw_instance.comment_and_reply_dict_to_df(comment_and_replies_dict)\n",
    "\n",
    "    # store df's in an intermediate list before combining into a df\n",
    "    full_comment_list.append(comment_df_at_post_i)\n",
    "    full_reply_list.append(reply_df_at_post_i)\n",
    "\n",
    "comment_table_df = pd.concat(full_comment_list, axis=0, ignore_index=True)\n",
    "reply_table_df = pd.concat(full_reply_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment table length 2377\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2377 entries, 0 to 2376\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   comment_id  2377 non-null   object\n",
      " 1   parent_id   2377 non-null   object\n",
      " 2   content     2377 non-null   object\n",
      " 3   upvotes     2377 non-null   int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 74.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>content</th>\n",
       "      <th>upvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g1lb1ef</td>\n",
       "      <td>t3_ia7s4c</td>\n",
       "      <td>NTA\\n\\nYou said he’d eat it or something, the ...</td>\n",
       "      <td>2853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g1lg7ks</td>\n",
       "      <td>t3_ia7s4c</td>\n",
       "      <td>NTA- What did they think was going to happen, ...</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g1laxsy</td>\n",
       "      <td>t3_ia7s4c</td>\n",
       "      <td>NTA. I mean, you told him not to give it to he...</td>\n",
       "      <td>19301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g1lave0</td>\n",
       "      <td>t3_ia7s4c</td>\n",
       "      <td>NTA. You hand a toddler a toy, not actual money.</td>\n",
       "      <td>3937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g1laydm</td>\n",
       "      <td>t3_ia7s4c</td>\n",
       "      <td>Lmaooo NTA-why give money in bare cash to a 1-...</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  parent_id                                            content  \\\n",
       "0    g1lb1ef  t3_ia7s4c  NTA\\n\\nYou said he’d eat it or something, the ...   \n",
       "1    g1lg7ks  t3_ia7s4c  NTA- What did they think was going to happen, ...   \n",
       "2    g1laxsy  t3_ia7s4c  NTA. I mean, you told him not to give it to he...   \n",
       "3    g1lave0  t3_ia7s4c   NTA. You hand a toddler a toy, not actual money.   \n",
       "4    g1laydm  t3_ia7s4c  Lmaooo NTA-why give money in bare cash to a 1-...   \n",
       "\n",
       "   upvotes  \n",
       "0     2853  \n",
       "1      597  \n",
       "2    19301  \n",
       "3     3937  \n",
       "4      709  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_table_df[\"comment_id\"] = comment_table_df[\"comment_id\"].astype(str)\n",
    "comment_table_df[\"parent_id\"] = comment_table_df[\"parent_id\"].astype(str)\n",
    "comment_table_df[\"content\"] = comment_table_df[\"content\"].astype(str)\n",
    "comment_table_df[\"upvotes\"] = comment_table_df[\"upvotes\"].astype(int)\n",
    "\n",
    "print(\"Comment table length\", len(comment_table_df))\n",
    "print(comment_table_df.info())\n",
    "comment_table_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reply table length 8118\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8118 entries, 0 to 8117\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   reply_id   8118 non-null   object\n",
      " 1   parent_id  8118 non-null   object\n",
      " 2   content    8118 non-null   object\n",
      " 3   upvotes    8118 non-null   int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 253.8+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>content</th>\n",
       "      <th>upvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g1myvit</td>\n",
       "      <td>t1_g1lb1ef</td>\n",
       "      <td>5 seconds ago*</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g1nj0tp</td>\n",
       "      <td>t1_g1lb1ef</td>\n",
       "      <td>Relative has a screw loose, its just plain stupid</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g1oh6th</td>\n",
       "      <td>t1_g1lb1ef</td>\n",
       "      <td>this is truly the year of r/LeopardsAteMyFace</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g1m6iz6</td>\n",
       "      <td>t1_g1lg7ks</td>\n",
       "      <td>that's some unrealistic toddler standards my k...</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g1mvoxy</td>\n",
       "      <td>t1_g1lg7ks</td>\n",
       "      <td>Invest in babycoin</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reply_id   parent_id                                            content  \\\n",
       "0  g1myvit  t1_g1lb1ef                                     5 seconds ago*   \n",
       "1  g1nj0tp  t1_g1lb1ef  Relative has a screw loose, its just plain stupid   \n",
       "2  g1oh6th  t1_g1lb1ef      this is truly the year of r/LeopardsAteMyFace   \n",
       "3  g1m6iz6  t1_g1lg7ks  that's some unrealistic toddler standards my k...   \n",
       "4  g1mvoxy  t1_g1lg7ks                                 Invest in babycoin   \n",
       "\n",
       "   upvotes  \n",
       "0      354  \n",
       "1       51  \n",
       "2        6  \n",
       "3      465  \n",
       "4       39  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply_table_df[\"reply_id\"] = reply_table_df[\"reply_id\"].astype(str)\n",
    "reply_table_df[\"parent_id\"] = reply_table_df[\"parent_id\"].astype(str)\n",
    "reply_table_df[\"content\"] = reply_table_df[\"content\"].astype(str)\n",
    "reply_table_df[\"upvotes\"] = reply_table_df[\"upvotes\"].astype(int)\n",
    "\n",
    "print(\"Reply table length\", len(reply_table_df))\n",
    "print(reply_table_df.info())\n",
    "reply_table_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Comments and Replies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12264.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5121.25it/s]\n"
     ]
    }
   ],
   "source": [
    "pandas_gbq.to_gbq(comment_table_df, comment_table_id, project_id=PROJ_NAME, if_exists=\"append\")\n",
    "pandas_gbq.to_gbq(reply_table_df, reply_table_id, project_id=PROJ_NAME, if_exists=\"append\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
