{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cstainsby/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull in my modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my modules \n",
    "from path import get_model_folder_path\n",
    "sys.path.append(get_model_folder_path())\n",
    "\n",
    "from model import Transformer\n",
    "from data_utils import data_process, batchify\n",
    "from model_utils import fit, predict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilize Torchtext tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iter was \"consumed\" by the process of building the vocab,\n",
    "# so we have to create it again\n",
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "train_data = data_process(train_iter, vocab, tokenizer)\n",
    "val_data = data_process(val_iter, vocab, tokenizer)\n",
    "test_data = data_process(test_iter, vocab, tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print shape of raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size: 102499\n",
      "Val Data Size: 21441\n",
      "Test Data Size: 24185\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Size:\", len(train_data))\n",
    "print(\"Val Data Size:\", len(val_data))\n",
    "print(\"Test Data Size:\", len(test_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_data, batch_size)\n",
    "val_data = batchify(val_data, eval_batch_size)\n",
    "test_data = batchify(test_data, eval_batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print shape of datasets\n",
    "Note that the format is torch.Size([ <sequence_length>, <batch_size>])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: torch.Size([102499, 20])\n",
      "Val Data Shape torch.Size([21441, 10])\n",
      "Test Data Shape: torch.Size([24185, 10])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Data Shape:\", train_data.shape)\n",
    "print(\"Val Data Shape\", val_data.shape)\n",
    "print(\"Test Data Shape:\", test_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Transformer(\n",
    "    num_tokens=len(vocab), \n",
    "    dim_model=, \n",
    "    num_heads=2, \n",
    "    num_encoder_layers=2, \n",
    "    num_decoder_layers=2, \n",
    "    dropout_p=0.2\n",
    ").to(device)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating model\n",
      "------------------------- Epoch 1 -------------------------\n",
      "X: tensor([[0, 4, 2, 3, 4, 3, 5, 3, 2, 1],\n",
      "        [0, 2, 2, 5, 5, 4, 2, 2, 3, 1],\n",
      "        [0, 2, 3, 2, 4, 3, 5, 2, 2, 1],\n",
      "        [0, 5, 4, 2, 2, 4, 4, 3, 5, 1],\n",
      "        [0, 2, 2, 2, 3, 4, 4, 5, 4, 1],\n",
      "        [0, 3, 3, 3, 3, 5, 3, 5, 4, 1],\n",
      "        [0, 4, 4, 3, 3, 4, 5, 3, 4, 1],\n",
      "        [0, 4, 3, 5, 4, 4, 5, 2, 5, 1],\n",
      "        [0, 5, 4, 3, 3, 2, 5, 4, 3, 1],\n",
      "        [0, 5, 2, 2, 2, 4, 5, 4, 3, 1],\n",
      "        [0, 3, 4, 3, 5, 5, 2, 4, 5, 1],\n",
      "        [0, 4, 4, 2, 2, 5, 3, 2, 2, 1],\n",
      "        [0, 2, 5, 5, 5, 3, 3, 2, 4, 1],\n",
      "        [0, 5, 5, 2, 2, 5, 5, 2, 4, 1],\n",
      "        [0, 2, 3, 4, 5, 2, 4, 5, 2, 1],\n",
      "        [0, 5, 2, 2, 4, 4, 5, 2, 3, 1]])\n",
      "y_input: tensor([[0, 5, 4, 4, 3, 4, 2, 3, 4],\n",
      "        [0, 2, 2, 2, 4, 3, 2, 5, 2],\n",
      "        [0, 5, 5, 2, 5, 5, 2, 2, 4],\n",
      "        [0, 5, 2, 4, 4, 3, 2, 4, 5],\n",
      "        [0, 2, 5, 4, 5, 4, 2, 2, 2],\n",
      "        [0, 4, 2, 4, 4, 3, 5, 5, 5],\n",
      "        [0, 2, 2, 3, 4, 4, 5, 3, 5],\n",
      "        [0, 3, 2, 2, 5, 4, 5, 2, 4],\n",
      "        [0, 4, 4, 5, 5, 2, 3, 2, 5],\n",
      "        [0, 3, 2, 2, 5, 2, 2, 4, 2],\n",
      "        [0, 2, 4, 2, 3, 4, 4, 3, 5],\n",
      "        [0, 3, 4, 2, 2, 5, 3, 3, 5],\n",
      "        [0, 4, 3, 4, 3, 4, 2, 4, 2],\n",
      "        [0, 5, 2, 3, 4, 2, 5, 4, 5],\n",
      "        [0, 5, 5, 5, 2, 3, 3, 5, 3],\n",
      "        [0, 2, 5, 3, 2, 4, 4, 4, 5]])\n",
      "tgt mask: tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "len X 16\n",
      "len y in 16\n",
      "len tgt mask 9\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m EPOCHS \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m----> 3\u001b[0m train_loss_list, validation_loss_list \u001b[39m=\u001b[39m fit(\n\u001b[1;32m      4\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m      5\u001b[0m     opt\u001b[39m=\u001b[39;49m opt,\n\u001b[1;32m      6\u001b[0m     loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[1;32m      7\u001b[0m     train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m      8\u001b[0m     val_dataloader\u001b[39m=\u001b[39;49mval_dataloader,\n\u001b[1;32m      9\u001b[0m     epochs\u001b[39m=\u001b[39;49mEPOCHS\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/class/dataProj/bonion/src/backend/model/model_utils.py:141\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, opt, loss_fn, train_dataloader, val_dataloader, epochs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m    139\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m25\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m25\u001b[39m)\n\u001b[0;32m--> 141\u001b[0m     train_loss \u001b[39m=\u001b[39m train_loop(model, opt, loss_fn, train_dataloader)\n\u001b[1;32m    142\u001b[0m     train_loss_list \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [train_loss]\n\u001b[1;32m    144\u001b[0m     validation_loss \u001b[39m=\u001b[39m validation_loop(model, loss_fn, val_dataloader)\n",
      "File \u001b[0;32m~/class/dataProj/bonion/src/backend/model/model_utils.py:77\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, opt, loss_fn, dataloader)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlen tgt mask\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlen\u001b[39m(tgt_mask))\n\u001b[1;32m     74\u001b[0m \u001b[39m# NOTE: \u001b[39;00m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[39m# Standard training except we pass in y_input and tgt_mask\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m pred \u001b[39m=\u001b[39m model(X, y_input, tgt_mask)\n\u001b[1;32m     79\u001b[0m \u001b[39m# Permute pred to have batch size first again\u001b[39;00m\n\u001b[1;32m     80\u001b[0m pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m)      \n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/class/dataProj/bonion/src/backend/model/basicModel.py:55\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, tgt_mask, src_pad_mask, tgt_pad_mask)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, src, tgt, tgt_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, src_pad_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tgt_pad_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     51\u001b[0m     \u001b[39m# Src size must be (batch_size, src sequence length)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[39m# Tgt size must be (batch_size, tgt sequence length)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m     \u001b[39m# Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding(src) \u001b[39m*\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_model)\n\u001b[1;32m     56\u001b[0m     tgt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(tgt) \u001b[39m*\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_model)\n\u001b[1;32m     57\u001b[0m     src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_encoder(src)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/sparse.py:160\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    161\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    162\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "train_loss_list, validation_loss_list = fit(\n",
    "    model=model,\n",
    "    opt= opt,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_iters = [i+1 for i in range(EPOCHS)]\n",
    "\n",
    "plot_axes = plt.axes()\n",
    "plot_axes.set_xticks(epoch_iters)\n",
    "\n",
    "plt.plot(epoch_iters, train_loss_list, label=\"training loss\")\n",
    "plt.plot(epoch_iters, validation_loss_list, label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new data with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we test some examples to observe how the model predicts\n",
    "examples = [\n",
    "    torch.tensor([[model.s, 0, 0, 0, 0, 0, 0, 0, 0, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 1, 0, 1, 0, 1, 0, 1, 0, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 0, 1, 0, 1, 0, 1, 0, 1, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 3]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[2, 0, 1, 3]], dtype=torch.long, device=device)\n",
    "]\n",
    "\n",
    "for idx, example in enumerate(examples):\n",
    "    result = predict(model, example)\n",
    "    print(f\"Example {idx}\")\n",
    "    print(f\"Input: {example.view(-1).tolist()[1:-1]}\")\n",
    "    print(f\"Continuation: {result[1:-1]}\")\n",
    "\n",
    "    print(\"len of prediction:\", len(result[1:-1]))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Text Generation\n",
    "Given our predictions above, let create a function which can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
